{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing data to file\n",
    "\n",
    "Typically, the last step in a web scrape job is to write your results to file. In this case, we're going write out the results to a CSV file, and to do that we'll use Python's built-in [`csv`](https://docs.python.org/3/library/csv.html) module.\n",
    "\n",
    "To start with, let's import our dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of time, here's the working code to scrape the death row inmates into lists from the previous notebook -- go ahead and run these three cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_page = requests.get('https://www.tdcj.state.tx.us/death_row/dr_offenders_on_dr.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(dr_page.text, 'html.parser')\n",
    "table = soup.find('table', {'class': 'tdcj_table'})\n",
    "rows = table.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in rows[1:]:\n",
    "    cells = item.find_all('td')\n",
    "    inmate_id = cells[0].text\n",
    "    link = 'https://www.tdcj.texas.gov/death_row/' + cells[1].a['href']\n",
    "    last = cells[2].text\n",
    "    first = cells[3].text\n",
    "    dob = cells[4].text\n",
    "    gender = cells[5].text\n",
    "    race = cells[6].text\n",
    "    intake_date = cells[7].text\n",
    "    county = cells[8].text\n",
    "    offense_date = cells[9].text\n",
    "    inmate_data = [inmate_id, link, last, first, dob, gender, race, intake_date, county, offense_date]\n",
    "    print(inmate_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write this data to a CSV using Python's `csv` module, the steps are:\n",
    "- Open a new file in \"write\" mode\n",
    "- Write the headers (which we will define)\n",
    "- As we loop over the rows of data and extract them, write the final list to file\n",
    "\n",
    "Let's start by defining a list of strings that will become our header row in the CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define headers\n",
    "headers = ['inmate_id', 'link', 'last', 'first', 'dob', 'gender',\n",
    "           'race', 'intake_date', 'county', 'offense_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open a new file, we'll use a `with` statement and the `open()` function with a few arguments to specify how we write to file:\n",
    "- `inmate-data.csv`: The name of the file to write to\n",
    "- `'w'`: specifies that we're opening the file in \"write\" mode\n",
    "- `newline=''`: This is a Windows-specific argument to ensure that we don't end up with a bunch of blank extra lines ðŸ™„\n",
    "- `encoding='utf-8'`: The file encoding\n",
    "\n",
    "We'll also specify a variable to give us a handle to the open file: `in_file`\n",
    "\n",
    "Next, we'll create a `csv.writer` object that will handle actually writing the data to file. Let's start by just writing the headers to our new file using the `writerow` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file to write to\n",
    "\n",
    "    # create a writer object\n",
    "\n",
    "    # write the list of headers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! Now we can whang in the data we scraped out of the page earlier -- copy and past the code in the cell above that begins `for item in rows[1:]:` underneath where the headers are being written. Then it's just a matter of trading out `print()` for `writer.writerow()`\n",
    "\n",
    "Proper indentation is key here! Everything under the `for` statement should be indented an extra four spaces, otherwise things will break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file to write to\n",
    "\n",
    "    # create a writer object\n",
    "\n",
    "    # write the headers\n",
    "\n",
    "    # start a for loop\n",
    "\n",
    "        # grab the list of cells in this row\n",
    "        # and the bits of data we've already figured out how to extract\n",
    "        \n",
    "        # ...\n",
    "\n",
    "        # build the list\n",
    "\n",
    "        # write the row to file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "\n",
    "In groups, [scrape the first page of this table of FDA warning letters](https://www.fda.gov/ICECI/EnforcementActions/WarningLetters/2018/default.htm) into a CSV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
